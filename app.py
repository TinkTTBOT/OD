import streamlit as st
import torch
import clip
from PIL import Image
import io
import base64

# --- C·∫•u h√¨nh trang ---
st.set_page_config(page_title="Ph√¢n lo·∫°i xe d·ª± √°n OD", page_icon="üöó", layout="centered")

# --- CSS tu·ª≥ ch·ªânh ---
st.markdown("""
    <style>
    body { background-color: #0E1117; color: white; }
    .stApp { background-color: #0E1117; }
    footer { visibility: hidden; }
    .copyright {
        text-align: center;
        font-size: 14px;
        color: #888;
        margin-top: 40px;
    }
    </style>
""", unsafe_allow_html=True)

# --- Ti√™u ƒë·ªÅ ch√≠nh ---
st.title("üöó Ph√¢n lo·∫°i lo·∫°i xe d·ª± √°n OD")
st.caption("Nh·∫≠n d·∫°ng c√°c lo·∫°i xe th√¥ng d·ª•ng b·∫±ng m√¥ h√¨nh AI CLIP c·ªßa OpenAI")

# --- T·∫£i m√¥ h√¨nh CLIP ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# --- Danh s√°ch c√°c lo·∫°i xe ---
labels = ["SUV", "HATCHBACK", "MINIVAN", "VAN", "PICKUP TRUCK", "SEDAN", "TRUCK", "BUS", "WAGON"]

# --- H∆∞·ªõng d·∫´n ---
st.markdown("üñºÔ∏è **B·∫°n c√≥ th·ªÉ ch·ªçn ·∫£nh ho·∫∑c d√°n tr·ª±c ti·∫øp (Ctrl + V) v√†o ƒë√¢y:**")

# --- Upload ho·∫∑c d√°n ·∫£nh ---
uploaded_file = st.file_uploader("üìÅ Ch·ªçn ·∫£nh xe", type=["jpg", "jpeg", "png"])

# --- D√°n ·∫£nh b·∫±ng clipboard (n·∫øu c√≥) ---
pasted_image_data = st.query_params.get("pasted_image", [None])[0]

if pasted_image_data:
    image_bytes = base64.b64decode(pasted_image_data.split(",")[1])
    image = Image.open(io.BytesIO(image_bytes))
elif uploaded_file is not None:
    image = Image.open(uploaded_file)
else:
    st.info("üìã D√°n ·∫£nh (Ctrl + V) ho·∫∑c t·∫£i ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    image = None

# --- N·∫øu c√≥ ·∫£nh ---
if image is not None:
    st.image(image, caption="·∫¢nh xe ƒë∆∞·ª£c t·∫£i l√™n", use_column_width=True)

    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh v√† d·ª± ƒëo√°n
    image_input = preprocess(image).unsqueeze(0).to(device)
    text_inputs = torch.cat([clip.tokenize(label) for label in labels]).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_inputs)
        logits_per_image, _ = model(image_input, text_inputs)
        probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]

    # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ---
    st.success("‚úÖ K·∫øt qu·∫£ ph√¢n lo·∫°i:")
    for label, prob in zip(labels, probs):
        st.write(f"**{label}**: {prob * 100:.2f}%")

# --- Th√™m JavaScript h·ªó tr·ª£ d√°n ·∫£nh ---
st.markdown("""
<script>
document.addEventListener('paste', async (event) => {
    const items = event.clipboardData.items;
    for (const item of items) {
        if (item.type.indexOf('image') !== -1) {
            const blob = item.getAsFile();
            const reader = new FileReader();
            reader.onload = function(e) {
                const base64Image = e.target.result;
                const queryParams = new URLSearchParams(window.location.search);
                queryParams.set("pasted_image", base64Image);
                window.location.search = queryParams.toString();
            };
            reader.readAsDataURL(blob);
        }
    }
});
</script>
""", unsafe_allow_html=True)

# --- B·∫£n quy·ªÅn ---
st.markdown("""
<div class="copyright">¬© B·∫£n quy·ªÅn b·ªüi <b>Dino (Thien)</b> ‚Äì C√¥ng ty <b>AIWORX</b></div>
""", unsafe_allow_html=True)
