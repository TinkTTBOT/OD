import streamlit as st
from PIL import Image
import torch
import open_clip

# Thiáº¿t láº­p cáº¥u hÃ¬nh trang cho chuyÃªn nghiá»‡p hÆ¡n
st.set_page_config(
    page_title="PhÃ¢n loáº¡i Xe hÆ¡i báº±ng AI (CLIP)",
    page_icon="ğŸš—",
    layout="wide" # Sá»­ dá»¥ng layout rá»™ng Ä‘á»ƒ táº­n dá»¥ng khÃ´ng gian mÃ n hÃ¬nh
)

# --- Táº£i model ---
@st.cache_resource
def load_model():
    # Sá»­ dá»¥ng 'ViT-B-32' nhÆ° báº¡n Ä‘Ã£ lÃ m, Ä‘Ã¢y lÃ  má»™t lá»±a chá»n tá»‘t cho tá»‘c Ä‘á»™
    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')
    tokenizer = open_clip.get_tokenizer('ViT-B-32')
    return model, preprocess, tokenizer

try:
    model, preprocess, tokenizer = load_model()
except Exception as e:
    st.error(f"âŒ Lá»—i khi táº£i mÃ´ hÃ¬nh: Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i máº¡ng hoáº·c thÆ° viá»‡n Ä‘Ã£ cÃ i Ä‘áº·t. Chi tiáº¿t: {e}")
    st.stop() # Dá»«ng á»©ng dá»¥ng náº¿u táº£i model tháº¥t báº¡i

# --- Danh sÃ¡ch nhÃ£n (Labels) ---
labels = [
    "SUV", "Sedan", "Truck", "Van", "Bus", "Pickup Truck",
    "Hatchback", "Minivan", "Wagon", "Coupe", "Convertible"
]
# Táº¡o prompt chuyÃªn nghiá»‡p hÆ¡n
prompts = [f"A photo of a {label} car" for label in labels]


# ===================================================================
# --- GIAO DIá»†N CHÃNH (MAIN UI) ---
# ===================================================================

st.title("ğŸš— PhÃ¢n loáº¡i Loáº¡i Xe Tá»± Ä‘á»™ng báº±ng AI")
st.markdown("Sá»­ dá»¥ng mÃ´ hÃ¬nh **CLIP (Contrastive Languageâ€“Image Pre-training)** Ä‘á»ƒ xÃ¡c Ä‘á»‹nh loáº¡i xe dá»±a trÃªn hÃ¬nh áº£nh. MÃ´ hÃ¬nh nÃ y ráº¥t máº¡nh máº½ trong viá»‡c hiá»ƒu cáº£ hÃ¬nh áº£nh vÃ  vÄƒn báº£n.")

# Táº¡o hai cá»™t Ä‘á»ƒ bá»‘ cá»¥c Ä‘áº¹p hÆ¡n
col1, col2 = st.columns([1, 1.5]) 

with col1:
    st.subheader("1. Táº£i lÃªn HÃ¬nh áº£nh Xe ğŸ“¸")
    uploaded_file = st.file_uploader(
        "ğŸ“ Chá»n áº£nh xe (.png, .jpg, .jpeg) tá»« thiáº¿t bá»‹ cá»§a báº¡n", 
        type=["png", "jpg", "jpeg"]
    )
    image = None
    
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file).convert("RGB")
            st.info("ğŸ’¡ Nháº¥n nÃºt 'PhÃ¢n loáº¡i' á»Ÿ cá»™t bÃªn cáº¡nh Ä‘á»ƒ xem káº¿t quáº£.")
        except Exception as e:
            st.error(f"âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ tá»‡p áº£nh. Lá»—i: {e}")
    else:
        st.warning("ğŸ‘‰ Vui lÃ²ng táº£i lÃªn má»™t áº£nh xe Ä‘á»ƒ báº¯t Ä‘áº§u.")


with col2:
    st.subheader("2. Káº¿t quáº£ PhÃ¢n loáº¡i & áº¢nh ğŸ“Š")
    
    if image is not None:
        # Hiá»ƒn thá»‹ áº£nh trong cá»™t 2, dÃ¹ng tham sá»‘ má»›i thay tháº¿ 'use_column_width'
        st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_container_width=True)
        
        # --- NÃºt phÃ¢n loáº¡i ---
        if st.button("ğŸ” Báº¯t Ä‘áº§u PhÃ¢n loáº¡i", use_container_width=True, type="primary"):
            
            with st.spinner("â³ Äang phÃ¢n tÃ­ch áº£nh vÃ  tÃ¬m Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá»›i cÃ¡c loáº¡i xe..."):
                try:
                    # Tiá»n xá»­ lÃ½ áº£nh
                    image_input = preprocess(image).unsqueeze(0)

                    # MÃ£ hÃ³a vÄƒn báº£n (labels/prompts)
                    text_inputs = tokenizer(prompts)
                    
                    with torch.no_grad():
                        image_features = model.encode_image(image_input)
                        text_features = model.encode_text(text_inputs)

                        # Chuáº©n hÃ³a vector
                        image_features /= image_features.norm(dim=-1, keepdim=True)
                        text_features /= text_features.norm(dim=-1, keepdim=True)

                        # TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine (logits)
                        probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)
                        probs = probs[0].tolist()

                        # --- Xá»­ lÃ½ Káº¿t quáº£ ---
                        top_idx = torch.argmax(torch.tensor(probs)).item()
                        top_label = labels[top_idx]
                        top_prob = probs[top_idx] * 100

                    st.success(f"ğŸ‰ **Káº¿t quáº£ ChÃ­nh:** Xe thuá»™c loáº¡i **{top_label}**")
                    st.metric(label="Äá»™ Tá»± Tin", value=f"{top_prob:.2f}%")

                    # Hiá»ƒn thá»‹ táº¥t cáº£ káº¿t quáº£ dÆ°á»›i dáº¡ng biá»ƒu Ä‘á»“
                    st.subheader("Chi tiáº¿t Äá»™ tÆ°Æ¡ng Ä‘á»“ng")
                    # Gá»™p káº¿t quáº£ vÃ o DataFrame (cho viá»‡c hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ tá»‘t hÆ¡n)
                    results = sorted(zip(labels, probs), key=lambda x: x[1], reverse=True)
                    
                    # Chuáº©n bá»‹ dá»¯ liá»‡u cho bar chart
                    chart_labels = [r[0] for r in results]
                    chart_probs = [r[1] for r in results]
                    
                    st.bar_chart({"Loáº¡i Xe": chart_labels, "XÃ¡c Suáº¥t": chart_probs}, x="Loáº¡i Xe", y="XÃ¡c Suáº¥t")
                    
                except Exception as e:
                    st.error(f"âŒ ÄÃ£ xáº£y ra lá»—i trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {e}")
                    
    else:
        st.info("áº¢nh sáº½ hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y sau khi báº¡n táº£i lÃªn.")
        
# ===================================================================
# --- FOOTER & Báº¢N QUYá»€N ---
# ===================================================================

st.markdown("---")
st.caption("""
    Â© Báº£n quyá»n thuá»™c vá» **Thiá»‡n, CÃ´ng ty AIWORKX**. 
    á»¨ng dá»¥ng Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn ná»n táº£ng Streamlit vÃ  mÃ´ hÃ¬nh thá»‹ giÃ¡c-ngÃ´n ngá»¯ **CLIP** (OpenAI/OpenCLIP).
""")
