import streamlit as st
import torch
import open_clip
from PIL import Image
import io, base64

# --- C·∫•u h√¨nh trang ---
st.set_page_config(page_title="Ph√¢n lo·∫°i xe d·ª± √°n OD", page_icon="üöó", layout="centered")

# --- CSS ---
st.markdown("""
    <style>
    body { background-color: #0E1117; color: white; }
    .stApp { background-color: #0E1117; }
    footer { visibility: hidden; }
    .copyright {
        text-align: center;
        font-size: 14px;
        color: #888;
        margin-top: 40px;
    }
    </style>
""", unsafe_allow_html=True)

st.title("üöó Ph√¢n lo·∫°i lo·∫°i xe d·ª± √°n OD")
st.caption("Nh·∫≠n d·∫°ng c√°c lo·∫°i xe th√¥ng d·ª•ng b·∫±ng m√¥ h√¨nh AI CLIP (OpenCLIP)")

# --- Load model ---
@st.cache_resource
def load_model():
    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
    tokenizer = open_clip.get_tokenizer('ViT-B-32')
    return model, preprocess, tokenizer

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess, tokenizer = load_model()
model.to(device)

labels = ["SUV", "HATCHBACK", "MINIVAN", "VAN", "PICKUP TRUCK", "SEDAN", "TRUCK", "BUS", "WAGON"]

# --- Session state ƒë·ªÉ l∆∞u ·∫£nh ---
if "image" not in st.session_state:
    st.session_state.image = None

# --- Upload ho·∫∑c paste base64 ---
uploaded_file = st.file_uploader("üìÅ Ch·ªçn ·∫£nh xe", type=["jpg", "jpeg", "png"])
paste_base64 = st.text_area("üìã D√°n ·∫£nh d∆∞·ªõi d·∫°ng base64 ·ªü ƒë√¢y (Ctrl+V) ho·∫∑c b·ªè tr·ªëng", height=50)

if uploaded_file:
    st.session_state.image = Image.open(uploaded_file)
elif paste_base64:
    try:
        image_bytes = base64.b64decode(paste_base64.split(",")[-1])
        st.session_state.image = Image.open(io.BytesIO(image_bytes))
    except:
        st.warning("‚ùå Base64 kh√¥ng h·ª£p l·ªá.")

image = st.session_state.image

# --- Hi·ªÉn th·ªã v√† ph√¢n lo·∫°i ---
if image:
    st.image(image, caption="·∫¢nh xe", use_column_width=True)
    image_input = preprocess(image).unsqueeze(0).to(device)
    text_tokens = tokenizer(labels).to(device)

    with torch.no_grad(), torch.cuda.amp.autocast():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_tokens)
        image_features /= image_features.norm(dim=-1, keepdim=True)
        text_features /= text_features.norm(dim=-1, keepdim=True)
        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = similarity[0].cpu().numpy()

    st.success("‚úÖ K·∫øt qu·∫£ ph√¢n lo·∫°i:")
    for label, prob in zip(labels, probs):
        st.write(f"**{label}**: {prob * 100:.2f}%")

# --- B·∫£n quy·ªÅn ---
st.markdown("""
<div class="copyright">¬© B·∫£n quy·ªÅn b·ªüi <b>Dino (Thien)</b> ‚Äì C√¥ng ty <b>AIWORX</b></div>
""", unsafe_allow_html=True)
