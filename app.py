import streamlit as st
from PIL import Image
import torch
import open_clip
import gc # Import th∆∞ vi·ªán Garbage Collector

# --- C·∫•u h√¨nh b·ªô nh·ªõ v√† PyTorch ---
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True
gc.collect()

st.set_page_config(
    # ƒê·ªïi ti√™u ƒë·ªÅ trang web ƒë·ªÉ chuy√™n nghi·ªáp h∆°n
    page_title="Ph√¢n lo·∫°i Xe h∆°i b·∫±ng AI (CLIP)",
    page_icon="üöó",
    layout="wide"
)

# --- T·∫£i model ---
@st.cache_resource
def load_model():
    """T·∫£i m√¥ h√¨nh CLIP v√† c√°c th√†nh ph·∫ßn li√™n quan, ∆∞u ti√™n CPU."""
    try:
        device = "cpu"
        model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai', device=device)
        tokenizer = open_clip.get_tokenizer('ViT-B-32')
        return model, preprocess, tokenizer, device
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng ho·∫∑c th∆∞ vi·ªán ƒë√£ c√†i ƒë·∫∑t. Chi ti·∫øt: {e}")
        st.stop()

model, preprocess, tokenizer, device = load_model()

# --- Danh s√°ch nh√£n (Labels) ---
labels = [
    "SUV", "Sedan", "Truck", "Van", "Bus", "Pickup Truck",
    "Hatchback", "Minivan", "Wagon", "Coupe", "Convertible"
]
prompts = [f"A photo of a {label} car" for label in labels]


# ===================================================================
# --- GIAO DI·ªÜN CH√çNH (MAIN UI) ---
# ===================================================================

st.title("üöó H·ªá th·ªëng Ph√¢n lo·∫°i Lo·∫°i Xe T·ª± ƒë·ªông (CLIP)")
st.markdown("B·∫°n c√≥ th·ªÉ nh·∫•n **Enter** sau khi t·∫£i ·∫£nh ƒë·ªÉ ph√¢n lo·∫°i.")

# S·ª¨A L·ªñI GIAO DI·ªÜN: D√πng t·ª∑ l·ªá [1, 2] ho·∫∑c [1, 2.5] ƒë·ªÉ c·ªôt 2 c√≥ nhi·ªÅu kh√¥ng gian h∆°n
col1, col2 = st.columns([1, 2]) # T·ªâ l·ªá 1:2 gi√∫p ·∫£nh v√† bi·ªÉu ƒë·ªì hi·ªÉn th·ªã ƒë·∫πp h∆°n
image = None 
submitted = False 

# --- B·∫Øt ƒë·∫ßu Form (Widget t·∫£i ·∫£nh v√† n√∫t) ---
with col1:
    with st.form("classification_form"):
        st.subheader("1. T·∫£i l√™n H√¨nh ·∫£nh Xe üì∏")
        
        uploaded_file = st.file_uploader(
            "üìÅ Ch·ªçn ·∫£nh xe (.png, .jpg, .jpeg) ho·∫∑c K√©o v√† Th·∫£ v√†o ƒë√¢y:", 
            type=["png", "jpg", "jpeg"],
            key="file_uploader"
        )
        
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file).convert("RGB")
                st.info("üí° ·∫¢nh ƒë√£ s·∫µn s√†ng. Nh·∫•n n√∫t **'B·∫Øt ƒë·∫ßu Ph√¢n lo·∫°i'** ho·∫∑c nh·∫•n ph√≠m **Enter**.")
            except Exception as e:
                st.error(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω t·ªáp ·∫£nh. L·ªói: {e}")
        else:
            st.warning("üëâ Vui l√≤ng t·∫£i l√™n m·ªôt ·∫£nh xe (ho·∫∑c k√©o th·∫£) ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

        submitted = st.form_submit_button("üîç B·∫Øt ƒë·∫ßu Ph√¢n lo·∫°i", use_container_width=True, type="primary")

# --- Logic Hi·ªÉn th·ªã ·∫¢nh v√† K·∫øt qu·∫£ (T·∫•t c·∫£ ·ªü C·ªôt 2) ---
with col2:
    st.subheader("2. K·∫øt qu·∫£ Ph√¢n lo·∫°i & ·∫¢nh üìä")
    
    # --- X·ª≠ l√Ω logic Ph√¢n lo·∫°i sau khi form ƒë∆∞·ª£c g·ª≠i (b·∫±ng n√∫t ho·∫∑c Enter) ---
    if submitted:
        if image is not None:
            st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)

            with st.spinner("‚è≥ ƒêang ph√¢n t√≠ch ·∫£nh v√† t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng..."):
                try:
                    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh v√† chuy·ªÉn sang device
                    image_input = preprocess(image).unsqueeze(0).to(device)
                    text_inputs = tokenizer(prompts).to(device)
                    
                    with torch.no_grad():
                        image_features = model.encode_image(image_input)
                        text_features = model.encode_text(text_inputs)
                        image_features /= image_features.norm(dim=-1, keepdim=True)
                        text_features /= text_features.norm(dim=-1, keepdim=True)
                        probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)
                        probs = probs[0].tolist()

                        top_idx = torch.argmax(torch.tensor(probs)).item()
                        top_label = labels[top_idx]
                        top_prob = probs[top_idx] * 100

                    st.success(f"üéâ **K·∫øt qu·∫£ Ch√≠nh:** Xe thu·ªôc lo·∫°i **{top_label}**")
                    st.metric(label="ƒê·ªô T·ª± Tin (Confidence)", value=f"{top_prob:.2f}%")

                    st.subheader("Chi ti·∫øt ƒê·ªô T∆∞∆°ng ƒê·ªìng:")
                    results_data = sorted(zip(labels, probs), key=lambda x: x[1], reverse=True)
                    chart_labels = [r[0] for r in results_data]
                    chart_probs = [r[1] for r in results_data]
                    st.bar_chart({"Lo·∫°i Xe": chart_labels, "X√°c Su·∫•t": chart_probs}, x="Lo·∫°i Xe", y="X√°c Su·∫•t")
                    
                except Exception as e:
                    st.error(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh ph√¢n t√≠ch: {e}")
                
                finally:
                    # D·ªçn d·∫πp b·ªô nh·ªõ sau khi t√≠nh to√°n
                    gc.collect() 
                    if 'image_input' in locals(): del image_input
                    if 'text_inputs' in locals(): del text_inputs
                    if 'image_features' in locals(): del image_features
                    if 'text_features' in locals(): del text_features
                    if device == "cuda": torch.cuda.empty_cache()

        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n ·∫£nh tr∆∞·ªõc khi nh·∫•n Ph√¢n lo·∫°i (ho·∫∑c Enter).")

    # Hi·ªÉn th·ªã placeholder n·∫øu ch∆∞a c√≥ ·∫£nh v√† ch∆∞a nh·∫•n submit l·∫ßn n√†o
    elif image is None and not submitted:
        st.info("·∫¢nh xe c·ªßa b·∫°n v√† k·∫øt qu·∫£ ph√¢n lo·∫°i s·∫Ω hi·ªÉn th·ªã t·∫°i ƒë√¢y.")
    
    # N·∫øu ·∫£nh ƒë√£ t·∫£i l√™n nh∆∞ng ch∆∞a nh·∫•n submit
    elif image is not None and not submitted:
        st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)


# ===================================================================
# --- FOOTER & B·∫¢N QUY·ªÄN ---
# ===================================================================

st.markdown("---")
st.caption("""
    ¬© B·∫£n quy·ªÅn thu·ªôc v·ªÅ **Thi·ªán, C√¥ng ty AIWORKX**. 
    ·ª®ng d·ª•ng ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n n·ªÅn t·∫£ng Streamlit v√† m√¥ h√¨nh th·ªã gi√°c-ng√¥n ng·ªØ **CLIP** (OpenAI/OpenCLIP).
""")
