import streamlit as st
import torch
import open_clip
from PIL import Image
import io
import base64

# --- Cáº¥u hÃ¬nh trang ---
st.set_page_config(
    page_title="PhÃ¢n loáº¡i xe dá»± Ã¡n OD",
    page_icon="ğŸš—",
    layout="centered",
)

# --- HÃ m táº£i mÃ´ hÃ¬nh ---
@st.cache_resource
def load_model():
    model, _, preprocess = open_clip.create_model_and_transforms(
        'ViT-B-32', pretrained='openai'
    )
    tokenizer = open_clip.get_tokenizer('ViT-B-32')
    return model, preprocess, tokenizer

model, preprocess, tokenizer = load_model()
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

# --- Giao diá»‡n ---
st.title("ğŸš— PhÃ¢n loáº¡i loáº¡i xe dá»± Ã¡n OD")
st.caption("Nháº­n dáº¡ng cÃ¡c loáº¡i xe thÃ´ng dá»¥ng báº±ng mÃ´ hÃ¬nh AI CLIP cá»§a OpenAI")

st.write("ğŸ“¸ Báº¡n cÃ³ thá»ƒ **chá»n áº£nh hoáº·c dÃ¡n trá»±c tiáº¿p (Ctrl + V)** vÃ o Ä‘Ã¢y:")

# --- Chá»©c nÄƒng táº£i hoáº·c dÃ¡n áº£nh ---
uploaded_file = st.file_uploader("ğŸ“‚ Chá»n áº£nh xe", type=["jpg", "jpeg", "png"])

# DÃ¡n áº£nh tá»« clipboard (base64)
pasted_image_data = st.experimental_get_query_params().get("pasted_image", [None])[0]

if pasted_image_data:
    image_bytes = base64.b64decode(pasted_image_data)
    uploaded_file = io.BytesIO(image_bytes)

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="áº¢nh Ä‘Ã£ chá»n", use_container_width=True)

    if st.button("ğŸ” PhÃ¢n loáº¡i"):
        with st.spinner("Äang xá»­ lÃ½ báº±ng AI..."):
            image_input = preprocess(image).unsqueeze(0).to(device)

            labels = [
                "sedan", "suv", "van", "minivan", "truck",
                "pickup truck", "bus", "hatchback", "wagon", "coupe"
            ]
            text_tokens = tokenizer(labels).to(device)

            with torch.no_grad():
                image_features = model.encode_image(image_input)
                text_features = model.encode_text(text_tokens)

                image_features /= image_features.norm(dim=-1, keepdim=True)
                text_features /= text_features.norm(dim=-1, keepdim=True)

                similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
                values, indices = similarity[0].topk(len(labels))

            st.success("âœ… Káº¿t quáº£ phÃ¢n loáº¡i:")
            for idx, val in zip(indices, values):
                st.write(f"**{labels[idx].upper()}**: {val.item() * 100:.2f}%")

else:
    st.info("ğŸ‘‰ DÃ¡n áº£nh (Ctrl + V) hoáº·c táº£i áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u.")

# --- Footer báº£n quyá»n ---
st.markdown("""
<style>
footer {visibility: hidden;}
.footer-text {
    position: fixed;
    left: 0;
    bottom: 0;
    width: 100%;
    background-color: #f1f3f6;
    color: #333;
    text-align: center;
    padding: 10px;
    font-size: 14px;
    border-top: 1px solid #ddd;
}
</style>

<div class="footer-text">
    ğŸ„« 2025 Báº£n quyá»n thuá»™c vá» <b>Dino (Thien)</b> Â· CÃ´ng ty <b>AIWORX</b>
</div>
""", unsafe_allow_html=True)
